{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87a9bf-b624-422b-92ee-4ce242e254e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ========= CONFIG =========\n",
    "INPUT_FILE = \"students.xlsx\"          # Input Excel file with student data\n",
    "BRANCH_FOLDER = \"full_branch_wise\"    # Output folder for branch-wise split\n",
    "MIX_FOLDER = \"group_branch_wise_mix\"  # Output folder for mixed groups\n",
    "UNIFORM_FOLDER = \"group_uniform_mix\"  # Output folder for uniform groups\n",
    "FINAL_OUTPUT = \"output.xlsx\"          # Final stats Excel file\n",
    "# ===========================\n",
    "\n",
    "\n",
    "# ---------------- CODE 1 ----------------\n",
    "def students_branch_wise(file_path, output_folder=BRANCH_FOLDER):\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    if 'Roll' not in df.columns:\n",
    "        raise ValueError(\"The Excel file must contain a 'Roll' column.\")\n",
    "\n",
    "    # Extract branch from roll number\n",
    "    df['Branch'] = df['Roll'].astype(str).str[4:6]\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for branch, group in df.groupby('Branch'):\n",
    "        file_name = f\"{branch}.csv\"\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "        group[['Roll', 'Name', 'Email']].to_csv(output_path, index=False)\n",
    "        print(f\"[Code1] Saved {output_path}\")\n",
    "\n",
    "\n",
    "# ---------------- CODE 2 ----------------\n",
    "def students_group_mix(branch_folder=BRANCH_FOLDER,\n",
    "                       output_folder=MIX_FOLDER,\n",
    "                       num_groups=3):\n",
    "\n",
    "    branch_files = sorted([f for f in os.listdir(branch_folder) if f.endswith(\".csv\")])\n",
    "    if not branch_files:\n",
    "        raise ValueError(f\"No CSV files found in {branch_folder}\")\n",
    "\n",
    "    branches = {}\n",
    "    for f in branch_files:\n",
    "        branch = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(branch_folder, f), dtype=str)\n",
    "        df[\"Branch\"] = branch\n",
    "        branches[branch] = df.to_dict(\"records\")\n",
    "\n",
    "    total_students = sum(len(students) for students in branches.values())\n",
    "    base, rem = divmod(total_students, num_groups)\n",
    "    capacities = [base + (1 if i < rem else 0) for i in range(num_groups)]\n",
    "\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "\n",
    "    for g_idx in range(num_groups):\n",
    "        cap = capacities[g_idx]\n",
    "        while len(groups[g_idx]) < cap and any(branches.values()):\n",
    "            for b in list(branches.keys()):\n",
    "                if len(groups[g_idx]) >= cap:\n",
    "                    break\n",
    "                if branches[b]:\n",
    "                    student = branches[b].pop(0)\n",
    "                    groups[g_idx].append(student)\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i, rows in enumerate(groups, start=1):\n",
    "        gdf = pd.DataFrame(rows, columns=[\"Roll\", \"Name\", \"Email\", \"Branch\"])\n",
    "        gdf.to_csv(os.path.join(output_folder, f\"g{i}.csv\"), index=False)\n",
    "        print(f\"[Code2] Saved {output_folder}/g{i}.csv (total={len(gdf)})\")\n",
    "\n",
    "\n",
    "# ---------------- CODE 3 (your version) ----------------\n",
    "# ---------------- CODE 3 (updated uniform version) ----------------\n",
    "def students_group_uniform(branch_folder=BRANCH_FOLDER,\n",
    "                           output_folder=UNIFORM_FOLDER,\n",
    "                           num_groups=3):\n",
    "    # Collect branch CSVs\n",
    "    branch_files = [f for f in os.listdir(branch_folder) if f.endswith(\".csv\")]\n",
    "    if not branch_files:\n",
    "        raise ValueError(f\"No CSV files found in {branch_folder}\")\n",
    "\n",
    "    # Load all branches into dict {branch: df}\n",
    "    branches = {}\n",
    "    for f in branch_files:\n",
    "        branch = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(branch_folder, f), dtype=str)\n",
    "        df[\"Branch\"] = branch\n",
    "        branches[branch] = df\n",
    "\n",
    "    # Sort branches by size (largest first)\n",
    "    sorted_branches = sorted(branches.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    # Compute group sizes\n",
    "    total_students = sum(len(df) for df in branches.values())\n",
    "    group_size = total_students // num_groups\n",
    "    remainder = total_students % num_groups\n",
    "    group_limits = [group_size + (1 if i < remainder else 0) for i in range(num_groups)]\n",
    "\n",
    "    print(f\"[Code3] Total students: {total_students}\")\n",
    "    print(f\"[Code3] Target group size: {group_size} (+1 for first {remainder} groups)\")\n",
    "    print(f\"[Code3] Group limits: {group_limits}\")\n",
    "\n",
    "    # Prepare groups\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "    group_idx = 0\n",
    "    current_count = 0\n",
    "\n",
    "    # Distribute students, branch by branch (largest → smallest)\n",
    "    for branch, df in sorted_branches:\n",
    "        for _, student in df.iterrows():\n",
    "            if current_count >= group_limits[group_idx]:\n",
    "                # move to next group\n",
    "                group_idx += 1\n",
    "                current_count = 0\n",
    "                if group_idx >= num_groups:\n",
    "                    raise ValueError(\"More students than groups capacity (logic error)\")\n",
    "            groups[group_idx].append(student)\n",
    "            current_count += 1\n",
    "\n",
    "    # Save each group\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i, students in enumerate(groups, start=1):\n",
    "        if students:\n",
    "            gdf = pd.DataFrame(students)\n",
    "            gdf.to_csv(os.path.join(output_folder, f\"g{i}.csv\"), index=False)\n",
    "            print(f\"[Code3] Saved {output_folder}/g{i}.csv (total={len(gdf)})\")\n",
    "\n",
    "\n",
    "# ---------------- CODE 4 (your version) ----------------\n",
    "def generate_branch_stats(input_folder):\n",
    "    group_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "    if not group_files:\n",
    "        raise ValueError(f\"No CSV files found in {input_folder}\")\n",
    "\n",
    "    stats_list = []\n",
    "    all_branches = set()\n",
    "\n",
    "    for f in group_files:\n",
    "        df = pd.read_csv(os.path.join(input_folder, f), dtype=str)\n",
    "        all_branches.update(df[\"Branch\"].unique())\n",
    "\n",
    "    all_branches = sorted(all_branches)\n",
    "    all_columns = all_branches + [\"Total\"]\n",
    "\n",
    "    # preserve natural ordering of g1, g2, ..., g10, g11, etc.\n",
    "    for f in sorted(group_files, key=lambda x: (x[0], int(x[1:].split('.')[0]) if x[1:].split('.')[0].isdigit() else 999)):\n",
    "        group_name = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(input_folder, f), dtype=str)\n",
    "        counts = df[\"Branch\"].value_counts().to_dict()\n",
    "        row = [counts.get(branch, 0) for branch in all_branches]\n",
    "        row.append(len(df))\n",
    "        stats_list.append([group_name] + row)\n",
    "\n",
    "    return stats_list, all_columns\n",
    "\n",
    "\n",
    "def Generate_output(mix_folder=MIX_FOLDER, uniform_folder=UNIFORM_FOLDER, output_excel=FINAL_OUTPUT):\n",
    "    mix_stats, mix_columns = generate_branch_stats(mix_folder)\n",
    "    uniform_stats, uniform_columns = generate_branch_stats(uniform_folder)\n",
    "\n",
    "    all_columns = sorted(set(mix_columns + uniform_columns))\n",
    "    final_columns = [\"\"] + all_columns \n",
    "\n",
    "    mix_header = [[\"Mix\"] + all_columns]\n",
    "    uniform_header = [[\"Uniform\"] + all_columns]\n",
    "\n",
    "    mix_rows = []\n",
    "    for row in mix_stats:\n",
    "        row_dict = dict(zip([\"Group\"] + mix_columns, row))\n",
    "        mix_rows.append([row_dict[\"Group\"]] + [row_dict.get(col, 0) for col in all_columns])\n",
    "\n",
    "    uniform_rows = []\n",
    "    for row in uniform_stats:\n",
    "        row_dict = dict(zip([\"Group\"] + uniform_columns, row))\n",
    "        uniform_rows.append([row_dict[\"Group\"]] + [row_dict.get(col, 0) for col in all_columns])\n",
    "\n",
    "    blank_rows = [[\"\"] * len(final_columns)] * 2\n",
    "\n",
    "    final_data = mix_header + mix_rows + blank_rows + uniform_header + uniform_rows\n",
    "    final_df = pd.DataFrame(final_data)\n",
    "\n",
    "    with pd.ExcelWriter(output_excel, engine=\"openpyxl\") as writer:\n",
    "        final_df.to_excel(writer, sheet_name=\"Stats\", index=False, header=False)\n",
    "\n",
    "    print(f\"[Code4] Stats saved to {output_excel} (sheet=Stats)\")\n",
    "\n",
    "\n",
    "# ---------------- PIPELINE RUN ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Starting full pipeline...\")\n",
    "\n",
    "    # ask user input\n",
    "    num_groups = int(input(\"Enter number of groups: \"))\n",
    "\n",
    "    students_branch_wise(INPUT_FILE, BRANCH_FOLDER)\n",
    "    students_group_mix(BRANCH_FOLDER, MIX_FOLDER, num_groups)\n",
    "    students_group_uniform(BRANCH_FOLDER, UNIFORM_FOLDER, num_groups)\n",
    "    Generate_output(MIX_FOLDER, UNIFORM_FOLDER, FINAL_OUTPUT)\n",
    "\n",
    "    print(\"✅ Pipeline completed! All folders/files generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376ff22-623d-4d33-af3d-ed271a186e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "INPUT_FILE = \"students.xlsx\"\n",
    "BRANCH_FOLDER = \"full_branch_wise\"\n",
    "MIX_FOLDER = \"group_branch_wise_mix\"\n",
    "UNIFORM_FOLDER = \"group_uniform_mix\"\n",
    "FINAL_OUTPUT = \"output.xlsx\"\n",
    "# ============================\n",
    "\n",
    "\n",
    "def students_branch_wise(file_path, output_folder=BRANCH_FOLDER):\n",
    "    \"\"\"\n",
    "    Split the Excel file into separate CSVs branch-wise.\n",
    "    Branch is extracted from characters [4:6] of Roll number.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    if \"Roll\" not in df.columns:\n",
    "        raise ValueError(\"Input must contain a 'Roll' column\")\n",
    "\n",
    "    df[\"Branch\"] = df[\"Roll\"].astype(str).str[4:6]\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for branch, group in df.groupby(\"Branch\"):\n",
    "        out_path = os.path.join(output_folder, f\"{branch}.csv\")\n",
    "        group[[\"Roll\", \"Name\", \"Email\"]].to_csv(out_path, index=False)\n",
    "        print(f\"Saved {out_path}\")\n",
    "\n",
    "\n",
    "def students_group_mix(branch_folder=BRANCH_FOLDER, output_folder=MIX_FOLDER, num_groups=3):\n",
    "    \"\"\"\n",
    "    Create mixed groups of students, distributing fairly across branches.\n",
    "    \"\"\"\n",
    "    branch_files = [f for f in os.listdir(branch_folder) if f.endswith(\".csv\")]\n",
    "    if not branch_files:\n",
    "        raise ValueError(f\"No CSVs found in {branch_folder}\")\n",
    "\n",
    "    branches = {}\n",
    "    for f in branch_files:\n",
    "        branch = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(branch_folder, f), dtype=str)\n",
    "        df[\"Branch\"] = branch\n",
    "        branches[branch] = df.to_dict(\"records\")\n",
    "\n",
    "    total = sum(len(students) for students in branches.values())\n",
    "    base, rem = divmod(total, num_groups)\n",
    "    group_sizes = [base + (1 if i < rem else 0) for i in range(num_groups)]\n",
    "\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "    for i, size in enumerate(group_sizes):\n",
    "        while len(groups[i]) < size and any(branches.values()):\n",
    "            for b in list(branches.keys()):\n",
    "                if len(groups[i]) >= size:\n",
    "                    break\n",
    "                if branches[b]:\n",
    "                    groups[i].append(branches[b].pop(0))\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i, rows in enumerate(groups, start=1):\n",
    "        df = pd.DataFrame(rows, columns=[\"Roll\", \"Name\", \"Email\", \"Branch\"])\n",
    "        df.to_csv(os.path.join(output_folder, f\"g{i}.csv\"), index=False)\n",
    "        print(f\"Group {i} saved ({len(df)} students)\")\n",
    "\n",
    "\n",
    "def students_group_uniform(branch_folder=BRANCH_FOLDER, output_folder=UNIFORM_FOLDER, num_groups=3):\n",
    "    \"\"\"\n",
    "    Create uniform groups by sorting branches (largest first)\n",
    "    and distributing students evenly across groups.\n",
    "    \"\"\"\n",
    "    branch_files = [f for f in os.listdir(branch_folder) if f.endswith(\".csv\")]\n",
    "    if not branch_files:\n",
    "        raise ValueError(f\"No CSVs found in {branch_folder}\")\n",
    "\n",
    "    branches = {}\n",
    "    for f in branch_files:\n",
    "        bname = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(branch_folder, f), dtype=str)\n",
    "        df[\"Branch\"] = bname\n",
    "        branches[bname] = df\n",
    "\n",
    "    sorted_branches = sorted(branches.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    total = sum(len(df) for df in branches.values())\n",
    "    base, rem = divmod(total, num_groups)\n",
    "    limits = [base + (1 if i < rem else 0) for i in range(num_groups)]\n",
    "\n",
    "    print(f\"Total students: {total}\")\n",
    "    print(f\"Group sizes: {limits}\")\n",
    "\n",
    "    groups, g_idx, count = [[] for _ in range(num_groups)], 0, 0\n",
    "    for _, df in sorted_branches:\n",
    "        for _, student in df.iterrows():\n",
    "            if count >= limits[g_idx]:\n",
    "                g_idx += 1\n",
    "                count = 0\n",
    "            groups[g_idx].append(student)\n",
    "            count += 1\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i, students in enumerate(groups, start=1):\n",
    "        if students:\n",
    "            pd.DataFrame(students).to_csv(os.path.join(output_folder, f\"g{i}.csv\"), index=False)\n",
    "            print(f\"Group {i} saved ({len(students)} students)\")\n",
    "\n",
    "\n",
    "def generate_branch_stats(input_folder):\n",
    "    \"\"\"\n",
    "    Generate stats: branch counts per group.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "    if not files:\n",
    "        raise ValueError(f\"No CSVs found in {input_folder}\")\n",
    "\n",
    "    branches = set()\n",
    "    for f in files:\n",
    "        df = pd.read_csv(os.path.join(input_folder, f), dtype=str)\n",
    "        branches.update(df[\"Branch\"].unique())\n",
    "\n",
    "    branches = sorted(branches)\n",
    "    cols = branches + [\"Total\"]\n",
    "\n",
    "    stats = []\n",
    "    # g1, g2, ..., g10 ordering\n",
    "    files = sorted(files, key=lambda x: int(x[1:].split(\".\")[0]) if x[1:].split(\".\")[0].isdigit() else 999)\n",
    "    for f in files:\n",
    "        gname = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(input_folder, f), dtype=str)\n",
    "        counts = df[\"Branch\"].value_counts().to_dict()\n",
    "        row = [counts.get(b, 0) for b in branches]\n",
    "        row.append(len(df))\n",
    "        stats.append([gname] + row)\n",
    "\n",
    "    return stats, cols\n",
    "\n",
    "\n",
    "def save_stats(mix_folder=MIX_FOLDER, uniform_folder=UNIFORM_FOLDER, output_excel=FINAL_OUTPUT):\n",
    "    \"\"\"\n",
    "    Save combined stats (Mix + Uniform) into an Excel file.\n",
    "    \"\"\"\n",
    "    mix_stats, mix_cols = generate_branch_stats(mix_folder)\n",
    "    uniform_stats, uniform_cols = generate_branch_stats(uniform_folder)\n",
    "\n",
    "    all_cols = sorted(set(mix_cols + uniform_cols))\n",
    "    header_mix = [[\"Mix\"] + all_cols]\n",
    "    header_uniform = [[\"Uniform\"] + all_cols]\n",
    "\n",
    "    mix_rows = []\n",
    "    for row in mix_stats:\n",
    "        data = dict(zip([\"Group\"] + mix_cols, row))\n",
    "        mix_rows.append([data[\"Group\"]] + [data.get(c, 0) for c in all_cols])\n",
    "\n",
    "    uniform_rows = []\n",
    "    for row in uniform_stats:\n",
    "        data = dict(zip([\"Group\"] + uniform_cols, row))\n",
    "        uniform_rows.append([data[\"Group\"]] + [data.get(c, 0) for c in all_cols])\n",
    "\n",
    "    final = header_mix + mix_rows + [[\"\"] * (len(all_cols) + 1)] * 2 + header_uniform + uniform_rows\n",
    "    final_df = pd.DataFrame(final)\n",
    "\n",
    "    with pd.ExcelWriter(output_excel, engine=\"openpyxl\") as writer:\n",
    "        final_df.to_excel(writer, sheet_name=\"Stats\", index=False, header=False)\n",
    "\n",
    "    print(f\"Stats written to {output_excel}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n = int(input(\"Enter number of groups: \"))\n",
    "    students_branch_wise(INPUT_FILE, BRANCH_FOLDER)\n",
    "    students_group_mix(BRANCH_FOLDER, MIX_FOLDER, n)\n",
    "    students_group_uniform(BRANCH_FOLDER, UNIFORM_FOLDER, n)\n",
    "    save_stats(MIX_FOLDER, UNIFORM_FOLDER, FINAL_OUTPUT)\n",
    "    print(\"All done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21995b3-3eed-4467-8f96-21f67fea31c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlitNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading streamlit-1.49.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.10.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.3/44.3 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.21.1)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91620\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/10.0 MB 3.3 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.2/10.0 MB 3.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.6/10.0 MB 4.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/10.0 MB 5.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 5.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/10.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.0/10.0 MB 6.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.4/10.0 MB 6.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.2/10.0 MB 7.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.8/10.0 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.3/10.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.6/10.0 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.1/10.0 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.3/10.0 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.0/10.0 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.8/10.0 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.6/10.0 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/10.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.6/10.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.0/10.0 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   ---------------------- ---------------- 419.8/731.2 kB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  727.0/731.2 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 731.2/731.2 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "   ---------------------------------------- 0.0/208.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 208.2/208.2 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/26.2 MB 17.5 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.1/26.2 MB 13.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.6/26.2 MB 12.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.1/26.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.7/26.2 MB 12.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 3.1/26.2 MB 11.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.4/26.2 MB 11.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.6/26.2 MB 10.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.9/26.2 MB 9.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.1/26.2 MB 9.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/26.2 MB 8.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.8/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.3/26.2 MB 8.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.7/26.2 MB 9.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.1/26.2 MB 8.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.4/26.2 MB 9.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.4/26.2 MB 9.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.4/26.2 MB 9.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.5/26.2 MB 8.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.9/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.4/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 9.0/26.2 MB 8.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.4/26.2 MB 8.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.0/26.2 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.5/26.2 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.0/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.6/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.0/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.4/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.8/26.2 MB 8.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.3/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.8/26.2 MB 9.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.3/26.2 MB 9.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.9/26.2 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.5/26.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.9/26.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.5/26.2 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.8/26.2 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.3/26.2 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.7/26.2 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.1/26.2 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.1/26.2 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.1/26.2 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.1/26.2 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.1/26.2 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.2/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.4/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.9/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.3/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.8/26.2 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.2/26.2 MB 8.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.7/26.2 MB 8.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.3/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.3/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.8/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.2/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.8/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.9/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/6.9 MB 10.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.8/6.9 MB 10.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.4/6.9 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.8/6.9 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.4/6.9 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.8/6.9 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.1/6.9 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.5/6.9 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.8/6.9 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/6.9 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.5/6.9 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.9/6.9 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.3/6.9 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.8/6.9 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.2/6.9 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.5/6.9 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.9 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.9/6.9 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.9/6.9 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "   ---------------------------------------- 0.0/79.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 79.1/79.1 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading narwhals-2.2.0-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.0 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 174.1/401.0 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 401.0/401.0 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, tenacity, smmap, pyarrow, narwhals, cachetools, blinker, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 cachetools-6.2.0 gitdb-4.0.12 gitpython-3.1.45 narwhals-2.2.0 pyarrow-21.0.0 pydeck-0.9.1 smmap-5.0.2 streamlit-1.49.0 tenacity-9.1.2 toml-0.10.2 watchdog-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\91620\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0d3fad-fdfb-4fea-8419-b811b82dc188",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "st.title(\"CSV to Excel & Folder Generator\")\n",
    "\n",
    "# Upload CSV file\n",
    "uploaded_file = st.file_uploader(\"Upload your CSV file\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    st.write(\"### Preview of Uploaded CSV\")\n",
    "    st.dataframe(df.head())\n",
    "\n",
    "    # Process CSV → Save as Excel\n",
    "    output_excel = \"output.xlsx\"\n",
    "    df.to_excel(output_excel, index=False)\n",
    "\n",
    "    # Create 3 folders\n",
    "    folders = [\"Folder1\", \"Folder2\", \"Folder3\"]\n",
    "    for folder in folders:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    st.success(\"✅ Generated: output.xlsx and 3 folders (Folder1, Folder2, Folder3)\")\n",
    "\n",
    "    # Download button for Excel\n",
    "    with open(output_excel, \"rb\") as f:\n",
    "        st.download_button(\"Download Excel File\", f, file_name=output_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54902483-df28-47bf-a0c3-d84dea49146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 23:48:58.671 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.673 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.674 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.675 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.685 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.689 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.690 Session state does not function when running a script without `streamlit run`\n",
      "2025-08-28 23:48:58.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-28 23:48:58.693 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# ----------------- Your Functions -----------------\n",
    "def students_branch_wise(file_path, output_folder):\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    if 'Roll' not in df.columns:\n",
    "        st.error(\"The Excel file must contain a 'Roll' column.\")\n",
    "        return\n",
    "\n",
    "    df['Branch'] = df['Roll'].astype(str).str[4:6]\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for branch, group in df.groupby('Branch'):\n",
    "        file_name = f\"{branch}.csv\"\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "        group[['Roll', 'Name', 'Email']].to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "def students_group_mix(branch_folder, output_folder, num_groups):\n",
    "    branch_files = sorted([f for f in os.listdir(branch_folder) if f.endswith(\".csv\")])\n",
    "    branches = {}\n",
    "    for f in branch_files:\n",
    "        branch = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(branch_folder, f), dtype=str)\n",
    "        df[\"Branch\"] = branch\n",
    "        branches[branch] = df.to_dict(\"records\")\n",
    "\n",
    "    total_students = sum(len(students) for students in branches.values())\n",
    "    base, rem = divmod(total_students, num_groups)\n",
    "    capacities = [base + (1 if i < rem else 0) for i in range(num_groups)]\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "\n",
    "    for g_idx in range(num_groups):\n",
    "        cap = capacities[g_idx]\n",
    "        while len(groups[g_idx]) < cap and any(branches.values()):\n",
    "            for b in list(branches.keys()):\n",
    "                if len(groups[g_idx]) >= cap:\n",
    "                    break\n",
    "                if branches[b]:\n",
    "                    student = branches[b].pop(0)\n",
    "                    groups[g_idx].append(student)\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i, rows in enumerate(groups, start=1):\n",
    "        gdf = pd.DataFrame(rows, columns=[\"Roll\", \"Name\", \"Email\", \"Branch\"])\n",
    "        gdf.to_csv(os.path.join(output_folder, f\"g{i}.csv\"), index=False)\n",
    "\n",
    "\n",
    "def students_group_uniform(branch_folder, output_folder, num_groups):\n",
    "    branch_files = [f for f in os.listdir(branch_folder) if f.endswith(\".csv\")]\n",
    "    branches = {}\n",
    "    for f in branch_files:\n",
    "        branch = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(branch_folder, f), dtype=str)\n",
    "        df[\"Branch\"] = branch\n",
    "        branches[branch] = df\n",
    "\n",
    "    sorted_branches = sorted(branches.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    total_students = sum(len(df) for df in branches.values())\n",
    "    group_size = total_students // num_groups\n",
    "    remainder = total_students % num_groups\n",
    "    group_limits = [group_size + (1 if i < remainder else 0) for i in range(num_groups)]\n",
    "\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "    group_idx, current_count = 0, 0\n",
    "\n",
    "    for branch, df in sorted_branches:\n",
    "        for _, student in df.iterrows():\n",
    "            if current_count >= group_limits[group_idx]:\n",
    "                group_idx += 1\n",
    "                current_count = 0\n",
    "            groups[group_idx].append(student)\n",
    "            current_count += 1\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i, students in enumerate(groups, start=1):\n",
    "        if students:\n",
    "            gdf = pd.DataFrame(students)\n",
    "            gdf.to_csv(os.path.join(output_folder, f\"g{i}.csv\"), index=False)\n",
    "\n",
    "\n",
    "def generate_branch_stats(input_folder):\n",
    "    group_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "    stats_list, all_branches = [], set()\n",
    "\n",
    "    for f in group_files:\n",
    "        df = pd.read_csv(os.path.join(input_folder, f), dtype=str)\n",
    "        all_branches.update(df[\"Branch\"].unique())\n",
    "\n",
    "    all_branches = sorted(all_branches)\n",
    "    all_columns = all_branches + [\"Total\"]\n",
    "\n",
    "    for f in sorted(group_files):\n",
    "        group_name = os.path.splitext(f)[0]\n",
    "        df = pd.read_csv(os.path.join(input_folder, f), dtype=str)\n",
    "        counts = df[\"Branch\"].value_counts().to_dict()\n",
    "        row = [counts.get(branch, 0) for branch in all_branches]\n",
    "        row.append(len(df))\n",
    "        stats_list.append([group_name] + row)\n",
    "\n",
    "    return stats_list, all_columns\n",
    "\n",
    "\n",
    "def Generate_output(mix_folder, uniform_folder, output_excel):\n",
    "    mix_stats, mix_columns = generate_branch_stats(mix_folder)\n",
    "    uniform_stats, uniform_columns = generate_branch_stats(uniform_folder)\n",
    "\n",
    "    all_columns = sorted(set(mix_columns + uniform_columns))\n",
    "    final_columns = [\"\"] + all_columns\n",
    "    mix_header = [[\"Mix\"] + all_columns]\n",
    "    uniform_header = [[\"Uniform\"] + all_columns]\n",
    "\n",
    "    mix_rows = []\n",
    "    for row in mix_stats:\n",
    "        row_dict = dict(zip([\"Group\"] + mix_columns, row))\n",
    "        mix_rows.append([row_dict[\"Group\"]] + [row_dict.get(col, 0) for col in all_columns])\n",
    "\n",
    "    uniform_rows = []\n",
    "    for row in uniform_stats:\n",
    "        row_dict = dict(zip([\"Group\"] + uniform_columns, row))\n",
    "        uniform_rows.append([row_dict[\"Group\"]] + [row_dict.get(col, 0) for col in all_columns])\n",
    "\n",
    "    blank_rows = [[\"\"] * len(final_columns)] * 2\n",
    "    final_data = mix_header + mix_rows + blank_rows + uniform_header + uniform_rows\n",
    "    final_df = pd.DataFrame(final_data)\n",
    "\n",
    "    with pd.ExcelWriter(output_excel, engine=\"openpyxl\") as writer:\n",
    "        final_df.to_excel(writer, sheet_name=\"Stats\", index=False, header=False)\n",
    "\n",
    "# ----------------- Streamlit App -----------------\n",
    "st.title(\"📊 Student Grouping App\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload Excel file (must contain 'Roll' column)\", type=[\"xlsx\"])\n",
    "num_groups = st.number_input(\"Enter number of groups:\", min_value=2, max_value=20, value=3, step=1)\n",
    "\n",
    "if uploaded_file and st.button(\"Generate Groups\"):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        input_path = os.path.join(tmpdir, \"students.xlsx\")\n",
    "        with open(input_path, \"wb\") as f:\n",
    "            f.write(uploaded_file.read())\n",
    "\n",
    "        branch_folder = os.path.join(tmpdir, \"full_branch_wise\")\n",
    "        mix_folder = os.path.join(tmpdir, \"group_branch_wise_mix\")\n",
    "        uniform_folder = os.path.join(tmpdir, \"group_uniform_mix\")\n",
    "        output_excel = os.path.join(tmpdir, \"output.xlsx\")\n",
    "\n",
    "        students_branch_wise(input_path, branch_folder)\n",
    "        students_group_mix(branch_folder, mix_folder, num_groups)\n",
    "        students_group_uniform(branch_folder, uniform_folder, num_groups)\n",
    "        Generate_output(mix_folder, uniform_folder, output_excel)\n",
    "\n",
    "        with open(output_excel, \"rb\") as f:\n",
    "            st.download_button(\"⬇️ Download Final Output (Excel)\", f, file_name=\"output.xlsx\")\n",
    "\n",
    "        st.success(\"✅ Groups generated and stats compiled!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e056326e-f6bc-4d36-9552-25400f82ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run tut01.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e06ca-f2f1-4c51-92de-8bfa52d4aeed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
